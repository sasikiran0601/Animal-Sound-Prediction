# ğŸ¾ Animal Sound Classification System

A complete deep learning pipeline for classifying animal sounds using Convolutional Neural Networks (CNN) and spectrograms.

## ğŸ“‹ Overview

This project converts audio files (.wav, .mp3) into mel-spectrograms and uses a CNN model to classify which animal the sound belongs to. The system includes both a command-line interface and a modern web frontend for easy audio classification.

**NEW**: ğŸŒ **Web Frontend** - Upload audio files through a beautiful web interface and get instant predictions!

## ğŸ¯ Features

- **ğŸŒ Web Frontend**: Modern, responsive web interface with drag-and-drop upload
- **Audio to Spectrogram Conversion**: Converts audio files to mel-spectrograms
- **CNN Model Training**: Deep learning model with 8+ layers
- **Multi-class Classification**: Supports 15 animal species
- **High Accuracy**: Achieves good accuracy with data augmentation
- **Easy Prediction**: Simple interface to classify new audio files
- **Real-time Results**: Instant predictions with confidence scores

## ğŸ—ï¸ Architecture

```
Audio File (.wav/.mp3)
    â†“
Preprocessing (3 seconds, 22050 Hz)
    â†“
Mel-Spectrogram Generation (128 mel bands)
    â†“
CNN Model (VGG-inspired architecture)
    â†“
Animal Classification Output
```

## ï¿½ Supported Animal Classes

The model can detect **15 different animal sounds**:

1. ğŸ» Bear
2. ğŸ¦ Bird
3. ğŸ± Cat
4. ğŸ® Cow
5. ğŸ¦… Crow
6. ğŸ• Dog
7. ğŸ¸ Frog
8. ğŸ” Hen
9. ğŸ¦— Insects
10. ğŸ¦ Lion
11. ğŸ· Pig
12. ğŸ“ Rooster
13. ğŸ‘ Sheep
14. ğŸ¦ Humming-bird
15. ğŸ“Š Sample

## ğŸ“¦ Dataset

### Download from Kaggle

The complete dataset is hosted on Kaggle for easy access:

**ğŸµ [Animal Sound Dataset on Kaggle](https://www.kaggle.com/datasets/sasikiran0601/animaldataset)**

This includes:
- 46,162+ audio files (.wav format)
- 15 animal classes
- Pre-processed spectrograms
- Trained CNN model (best_model.h5)

### Quick Download

**Option 1: Download via Kaggle Website**
1. Visit: https://www.kaggle.com/datasets/sasikiran0601/animaldataset
2. Click "Download" button
3. Extract to your project folder

**Option 2: Download via Kaggle CLI**
```bash
# Install Kaggle CLI
pip install kaggle

# Download dataset
kaggle datasets download -d sasikiran0601/animaldataset

# Extract
unzip animaldataset.zip
```

> **Note**: The trained model is included in this repository, so you can start using the web app immediately without downloading the full dataset!

---

## ğŸ“¦ Installation

1. **Install Python 3.8+**

2. **Install required packages:**
```bash
pip install -r requirements.txt
```

Required packages:
- `tensorflow` - Deep learning framework
- `librosa` - Audio processing
- `numpy` - Numerical computing
- `matplotlib` - Plotting
- `flask` - Web server
- `flask-cors` - CORS support

## ğŸš€ Usage

### ğŸŒ Quick Start: Web Interface (Recommended)

The easiest way to use the animal sound classifier:

```bash
python app.py
```

Then open your browser to: **http://localhost:5000**

- Drag and drop an audio file (MP3, WAV, FLAC, OGG, M4A)
- Click "Predict Animal"
- See results with confidence scores for all 15 animal classes!

---

### ğŸ“š Advanced: Command Line Interface

### Step 1: Generate Spectrograms

Process audio files and generate spectrograms for training:

```bash
python 1_generate_spectrograms.py
```

This will:
- Read 100 audio samples from `mini_project/sounds.csv`
- Generate mel-spectrograms (128x128 images)
- Save organized by animal class in `spectrograms_dataset/`

### Step 2: Train the Model

Train the CNN model on generated spectrograms:

```bash
python 2_train_model.py
```

This will:
- Load spectrograms from `spectrograms_dataset/`
- Build a CNN model with ~2M parameters
- Train for up to 50 epochs with early stopping
- Save the best model to `trained_model/animal_sound_classifier.h5`
- Generate training history plots

### Step 3: Predict New Audio

Classify a new audio file:

```bash
python 3_predict.py path/to/your/audio.wav
```

Or run interactively:
```bash
python 3_predict.py
```

## ğŸ“Š Model Architecture

```
Input: 128x128x3 RGB Spectrogram Image

Block 1: Conv2D(32) â†’ BatchNorm â†’ Conv2D(32) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)
Block 2: Conv2D(64) â†’ BatchNorm â†’ Conv2D(64) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)
Block 3: Conv2D(128) â†’ BatchNorm â†’ Conv2D(128) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)
Block 4: Conv2D(256) â†’ BatchNorm â†’ Conv2D(256) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)

Flatten
Dense(512) â†’ BatchNorm â†’ Dropout(0.5)
Dense(256) â†’ BatchNorm â†’ Dropout(0.5)
Dense(num_classes, softmax)

Total Parameters: ~2,000,000
```

## ğŸµ Audio Processing Parameters

- **Sample Rate**: 22,050 Hz
- **Duration**: 3 seconds (fixed)
- **Mel Bands**: 128
- **Hop Length**: 512
- **FFT Window**: 2048
- **Frequency Range**: 0 - 11,025 Hz

## ğŸ“ Project Structure

```
AnimalVoicedetection/
â”œâ”€â”€ static/                    # Web frontend files
â”‚   â”œâ”€â”€ index.html            # Main web page
â”‚   â”œâ”€â”€ style.css             # Premium styling
â”‚   â””â”€â”€ script.js             # Interactive functionality
â”œâ”€â”€ mini_project/              # Original audio files and CSV
â”‚   â”œâ”€â”€ sounds.csv            # Audio metadata
â”‚   â””â”€â”€ *.wav                 # Audio files
â”œâ”€â”€ spectrograms_dataset/      # Generated spectrograms
â”‚   â”œâ”€â”€ Lion/
â”‚   â”œâ”€â”€ Bear/
â”‚   â”œâ”€â”€ Cat/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ trained_model/             # Trained model and artifacts
â”‚   â”œâ”€â”€ best_model.h5         # Trained CNN model
â”‚   â”œâ”€â”€ class_labels.json     # Animal class labels
â”‚   â”œâ”€â”€ training_history.json
â”‚   â””â”€â”€ training_history.png
â”œâ”€â”€ uploads/                   # Temporary upload folder (auto-created)
â”œâ”€â”€ app.py                     # Flask web server
â”œâ”€â”€ 1_generate_spectrograms.py # Step 1: Generate spectrograms
â”œâ”€â”€ 2_train_model.py           # Step 2: Train CNN model
â”œâ”€â”€ 3_predict.py               # Step 3: Predict new audio (CLI)
â”œâ”€â”€ 4_batch_predict.py         # Batch prediction script
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # This file
```

## ğŸ“ Training Details

- **Optimizer**: Adam (learning rate: 0.001)
- **Loss Function**: Categorical Cross-Entropy
- **Batch Size**: 32
- **Epochs**: 50 (with early stopping)
- **Validation Split**: 20%
- **Data Augmentation**: 
  - Rotation (Â±10Â°)
  - Width/Height shift (Â±10%)
  - Horizontal flip
  - Zoom (Â±10%)

## ğŸ“ˆ Expected Results

- **Training Accuracy**: 85-95%
- **Validation Accuracy**: 75-90%
- **Inference Time**: ~0.5 seconds per audio file

## ğŸ› Troubleshooting

### Issue: "Audio file not found"
- Ensure audio files are in `mini_project/` directory
- Check CSV file paths match actual file locations

### Issue: "Model not found"
- Run `2_train_model.py` before `3_predict.py`

### Issue: Low accuracy
- Increase training samples per class (aim for 50+ per class)
- Increase training epochs
- Adjust learning rate

## ğŸ”§ Customization

### Change Audio Duration
Edit in all three scripts:
```python
DURATION = 5  # Change from 3 to 5 seconds
```

### Change Image Size
Edit in all three scripts:
```python
IMG_SIZE = (256, 256)  # Change from (128, 128)
```

### Add More Animals
Simply add more audio files with naming pattern: `AnimalName_X.wav`

## ğŸ“ Example Output

```
PREDICTION RESULTS
============================================================
ğŸ¾ Predicted Animal: Lion
ğŸ¯ Confidence: 94.32%

ğŸ“Š All Class Probabilities:
  Lion            94.32% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  Bear             3.21% â–ˆ
  Dog              1.45% 
  Cat              0.67% 
  Cow              0.35% 
============================================================
```

## ğŸ¤ Contributing

Feel free to:
- Add more animal classes
- Improve model architecture
- Add more audio preprocessing techniques
- Implement real-time audio classification

## ğŸ“„ License

This project is for educational purposes.

## ğŸ™ Acknowledgments

- Librosa for audio processing
- TensorFlow/Keras for deep learning
- Animal sound datasets from various sources

---

**Made with â¤ï¸ for Animal Sound Classification**
