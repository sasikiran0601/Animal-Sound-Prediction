# ğŸ—ï¸ System Architecture - Animal Sound Classifier

## ğŸ“Š Complete System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ANIMAL SOUND CLASSIFICATION SYSTEM                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: DATA PREPARATION (1_generate_spectrograms.py)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  Input: sounds.csv + Audio Files (.wav)                             â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â”œâ”€â–º Read CSV metadata (100 samples)                             â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â”œâ”€â–º For each audio file:                                        â”‚
â”‚     â”‚   â”œâ”€â–º Load audio (librosa)                                    â”‚
â”‚     â”‚   â”œâ”€â–º Resample to 22050 Hz                                    â”‚
â”‚     â”‚   â”œâ”€â–º Trim/Pad to 3 seconds                                   â”‚
â”‚     â”‚   â”œâ”€â–º Generate Mel-Spectrogram (128 mel bands)               â”‚
â”‚     â”‚   â”œâ”€â–º Convert to dB scale                                     â”‚
â”‚     â”‚   â””â”€â–º Save as 128x128 PNG image                              â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â””â”€â–º Output: spectrograms_dataset/                               â”‚
â”‚         â”œâ”€â–º Lion/ (50 images)                                       â”‚
â”‚         â”œâ”€â–º Bear/ (50 images)                                       â”‚
â”‚         â””â”€â–º ... (other animals)                                     â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: MODEL TRAINING (2_train_model.py)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  Input: spectrograms_dataset/                                        â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â”œâ”€â–º Load images with ImageDataGenerator                         â”‚
â”‚     â”‚   â”œâ”€â–º Training set (80%) with augmentation                   â”‚
â”‚     â”‚   â”‚   â”œâ”€â–º Rotation (Â±10Â°)                                     â”‚
â”‚     â”‚   â”‚   â”œâ”€â–º Shift (Â±10%)                                        â”‚
â”‚     â”‚   â”‚   â”œâ”€â–º Zoom (Â±10%)                                         â”‚
â”‚     â”‚   â”‚   â””â”€â–º Horizontal flip                                     â”‚
â”‚     â”‚   â”‚                                                             â”‚
â”‚     â”‚   â””â”€â–º Validation set (20%) without augmentation              â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â”œâ”€â–º Build CNN Model                                             â”‚
â”‚     â”‚   â”‚                                                             â”‚
â”‚     â”‚   â”‚   INPUT: 128x128x3 RGB Image                             â”‚
â”‚     â”‚   â”‚      â”‚                                                     â”‚
â”‚     â”‚   â”‚      â”œâ”€â–º BLOCK 1: Conv2D(32) â†’ BN â†’ Conv2D(32) â†’ BN     â”‚
â”‚     â”‚   â”‚      â”‚              â†’ MaxPool(2x2) â†’ Dropout(0.25)       â”‚
â”‚     â”‚   â”‚      â”‚                                                     â”‚
â”‚     â”‚   â”‚      â”œâ”€â–º BLOCK 2: Conv2D(64) â†’ BN â†’ Conv2D(64) â†’ BN     â”‚
â”‚     â”‚   â”‚      â”‚              â†’ MaxPool(2x2) â†’ Dropout(0.25)       â”‚
â”‚     â”‚   â”‚      â”‚                                                     â”‚
â”‚     â”‚   â”‚      â”œâ”€â–º BLOCK 3: Conv2D(128) â†’ BN â†’ Conv2D(128) â†’ BN   â”‚
â”‚     â”‚   â”‚      â”‚              â†’ MaxPool(2x2) â†’ Dropout(0.25)       â”‚
â”‚     â”‚   â”‚      â”‚                                                     â”‚
â”‚     â”‚   â”‚      â”œâ”€â–º BLOCK 4: Conv2D(256) â†’ BN â†’ Conv2D(256) â†’ BN   â”‚
â”‚     â”‚   â”‚      â”‚              â†’ MaxPool(2x2) â†’ Dropout(0.25)       â”‚
â”‚     â”‚   â”‚      â”‚                                                     â”‚
â”‚     â”‚   â”‚      â”œâ”€â–º Flatten                                          â”‚
â”‚     â”‚   â”‚      â”‚                                                     â”‚
â”‚     â”‚   â”‚      â”œâ”€â–º Dense(512) â†’ BN â†’ Dropout(0.5)                  â”‚
â”‚     â”‚   â”‚      â”‚                                                     â”‚
â”‚     â”‚   â”‚      â”œâ”€â–º Dense(256) â†’ BN â†’ Dropout(0.5)                  â”‚
â”‚     â”‚   â”‚      â”‚                                                     â”‚
â”‚     â”‚   â”‚      â””â”€â–º Dense(num_classes) â†’ Softmax                    â”‚
â”‚     â”‚   â”‚                                                             â”‚
â”‚     â”‚   â”‚   OUTPUT: Probability distribution over animal classes    â”‚
â”‚     â”‚   â”‚                                                             â”‚
â”‚     â”‚   â””â”€â–º Compile with Adam optimizer                             â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â”œâ”€â–º Train Model                                                 â”‚
â”‚     â”‚   â”œâ”€â–º Batch size: 32                                          â”‚
â”‚     â”‚   â”œâ”€â–º Epochs: up to 50                                        â”‚
â”‚     â”‚   â”œâ”€â–º Callbacks:                                              â”‚
â”‚     â”‚   â”‚   â”œâ”€â–º ModelCheckpoint (save best)                        â”‚
â”‚     â”‚   â”‚   â”œâ”€â–º EarlyStopping (patience=10)                        â”‚
â”‚     â”‚   â”‚   â””â”€â–º ReduceLROnPlateau (patience=5)                     â”‚
â”‚     â”‚   â”‚                                                             â”‚
â”‚     â”‚   â””â”€â–º Monitor validation accuracy                             â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â””â”€â–º Output: trained_model/                                      â”‚
â”‚         â”œâ”€â–º animal_sound_classifier.h5 (model)                     â”‚
â”‚         â”œâ”€â–º class_labels.json (label mapping)                      â”‚
â”‚         â”œâ”€â–º training_history.json (metrics)                        â”‚
â”‚         â””â”€â–º training_history.png (plots)                           â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: INFERENCE (3_predict.py)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  Input: New audio file (any_animal.wav)                             â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â”œâ”€â–º Load trained model (.h5)                                    â”‚
â”‚     â”œâ”€â–º Load class labels (.json)                                   â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â”œâ”€â–º Preprocess audio                                            â”‚
â”‚     â”‚   â”œâ”€â–º Load with librosa                                       â”‚
â”‚     â”‚   â”œâ”€â–º Resample to 22050 Hz                                    â”‚
â”‚     â”‚   â””â”€â–º Trim/Pad to 3 seconds                                   â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â”œâ”€â–º Generate spectrogram                                        â”‚
â”‚     â”‚   â”œâ”€â–º Mel-spectrogram (128 bands)                            â”‚
â”‚     â”‚   â”œâ”€â–º Convert to dB                                           â”‚
â”‚     â”‚   â””â”€â–º Save as temp image                                      â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â”œâ”€â–º Load and normalize image                                    â”‚
â”‚     â”‚   â”œâ”€â–º Resize to 128x128                                       â”‚
â”‚     â”‚   â”œâ”€â–º Normalize to [0, 1]                                     â”‚
â”‚     â”‚   â””â”€â–º Add batch dimension                                     â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â”œâ”€â–º Model prediction                                            â”‚
â”‚     â”‚   â””â”€â–º Forward pass through CNN                                â”‚
â”‚     â”‚                                                                 â”‚
â”‚     â””â”€â–º Output results                                              â”‚
â”‚         â”œâ”€â–º Predicted animal name                                   â”‚
â”‚         â”œâ”€â–º Confidence score (%)                                    â”‚
â”‚         â””â”€â–º All class probabilities                                 â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ Detailed Component Breakdown

### 1. Audio Preprocessing Pipeline

```
Raw Audio File
     â”‚
     â”œâ”€â–º librosa.load(sr=22050)
     â”‚   â””â”€â–º Converts any sample rate to 22050 Hz
     â”‚
     â”œâ”€â–º Duration normalization
     â”‚   â”œâ”€â–º If < 3s: Pad with zeros
     â”‚   â””â”€â–º If > 3s: Trim to 3s
     â”‚
     â””â”€â–º Output: numpy array [66150 samples]
```

### 2. Spectrogram Generation

```
Audio Signal [66150 samples]
     â”‚
     â”œâ”€â–º librosa.feature.melspectrogram()
     â”‚   â”œâ”€â–º n_mels = 128 (frequency bins)
     â”‚   â”œâ”€â–º hop_length = 512 (time steps)
     â”‚   â”œâ”€â–º n_fft = 2048 (FFT window)
     â”‚   â””â”€â–º fmax = 11025 Hz (Nyquist frequency)
     â”‚
     â”œâ”€â–º librosa.power_to_db()
     â”‚   â””â”€â–º Convert power to decibel scale
     â”‚
     â”œâ”€â–º Normalize to [0, 1]
     â”‚
     â””â”€â–º Output: 128x128 image (mel-frequency vs time)
```

### 3. CNN Architecture Details

```
Layer Type          Output Shape        Parameters    Activation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input               (128, 128, 3)       0             -
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Conv2D              (128, 128, 32)      896           ReLU
BatchNorm           (128, 128, 32)      128           -
Conv2D              (128, 128, 32)      9,248         ReLU
BatchNorm           (128, 128, 32)      128           -
MaxPooling2D        (64, 64, 32)        0             -
Dropout             (64, 64, 32)        0             -
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Conv2D              (64, 64, 64)        18,496        ReLU
BatchNorm           (64, 64, 64)        256           -
Conv2D              (64, 64, 64)        36,928        ReLU
BatchNorm           (64, 64, 64)        256           -
MaxPooling2D        (32, 32, 64)        0             -
Dropout             (32, 32, 64)        0             -
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Conv2D              (32, 32, 128)       73,856        ReLU
BatchNorm           (32, 32, 128)       512           -
Conv2D              (32, 32, 128)       147,584       ReLU
BatchNorm           (32, 32, 128)       512           -
MaxPooling2D        (16, 16, 128)       0             -
Dropout             (16, 16, 128)       0             -
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Conv2D              (16, 16, 256)       295,168       ReLU
BatchNorm           (16, 16, 256)       1,024         -
Conv2D              (16, 16, 256)       590,080       ReLU
BatchNorm           (16, 16, 256)       1,024         -
MaxPooling2D        (8, 8, 256)         0             -
Dropout             (8, 8, 256)         0             -
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Flatten             (16384)             0             -
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Dense               (512)               8,389,120     ReLU
BatchNorm           (512)               2,048         -
Dropout             (512)               0             -
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Dense               (256)               131,328       ReLU
BatchNorm           (256)               1,024         -
Dropout             (256)               0             -
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Dense               (num_classes)       varies        Softmax
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Parameters: ~9,700,000 (depends on num_classes)
Trainable Parameters: ~9,700,000
Non-trainable Parameters: 0
```

### 4. Training Process Flow

```
Epoch Loop (1 to 50)
     â”‚
     â”œâ”€â–º For each batch (32 images):
     â”‚   â”‚
     â”‚   â”œâ”€â–º Forward pass
     â”‚   â”‚   â”œâ”€â–º Input: batch of spectrograms
     â”‚   â”‚   â”œâ”€â–º CNN processing
     â”‚   â”‚   â””â”€â–º Output: predictions
     â”‚   â”‚
     â”‚   â”œâ”€â–º Calculate loss
     â”‚   â”‚   â””â”€â–º Categorical cross-entropy
     â”‚   â”‚
     â”‚   â”œâ”€â–º Backward pass
     â”‚   â”‚   â”œâ”€â–º Compute gradients
     â”‚   â”‚   â””â”€â–º Update weights (Adam optimizer)
     â”‚   â”‚
     â”‚   â””â”€â–º Update metrics
     â”‚       â”œâ”€â–º Training accuracy
     â”‚       â””â”€â–º Training loss
     â”‚
     â”œâ”€â–º Validation phase
     â”‚   â”œâ”€â–º Evaluate on validation set
     â”‚   â”œâ”€â–º Calculate validation loss
     â”‚   â””â”€â–º Calculate validation accuracy
     â”‚
     â”œâ”€â–º Callbacks
     â”‚   â”œâ”€â–º Save model if val_acc improved
     â”‚   â”œâ”€â–º Check early stopping condition
     â”‚   â””â”€â–º Reduce LR if plateau detected
     â”‚
     â””â”€â–º Next epoch or stop
```

### 5. Prediction Pipeline

```
New Audio File
     â”‚
     â”œâ”€â–º Preprocess (same as training)
     â”‚   â”œâ”€â–º Load audio
     â”‚   â”œâ”€â–º Normalize duration
     â”‚   â””â”€â–º Generate spectrogram
     â”‚
     â”œâ”€â–º Load trained model
     â”‚   â””â”€â–º Restore weights from .h5 file
     â”‚
     â”œâ”€â–º Forward pass
     â”‚   â”œâ”€â–º Input: single spectrogram
     â”‚   â”œâ”€â–º CNN processing
     â”‚   â””â”€â–º Output: probability vector
     â”‚
     â”œâ”€â–º Post-processing
     â”‚   â”œâ”€â–º argmax(probabilities) â†’ predicted class
     â”‚   â”œâ”€â–º max(probabilities) â†’ confidence
     â”‚   â””â”€â–º Map class index to animal name
     â”‚
     â””â”€â–º Display results
         â”œâ”€â–º Animal name
         â”œâ”€â–º Confidence %
         â””â”€â–º All class probabilities
```

---

## ğŸ“ Mathematical Operations

### Mel-Spectrogram Calculation

```
1. Short-Time Fourier Transform (STFT):
   X[m,k] = Î£ x[n] * w[n-m] * e^(-j2Ï€kn/N)
   where:
   - x[n] = audio signal
   - w[n] = window function
   - m = time frame
   - k = frequency bin

2. Power Spectrogram:
   P[m,k] = |X[m,k]|Â²

3. Mel Filterbank:
   M[i,k] = triangular filters on mel scale
   mel(f) = 2595 * logâ‚â‚€(1 + f/700)

4. Mel-Spectrogram:
   S[m,i] = Î£ P[m,k] * M[i,k]

5. dB Conversion:
   S_dB[m,i] = 10 * logâ‚â‚€(S[m,i] / ref)
```

### CNN Convolution Operation

```
Output[i,j,k] = Î£ Î£ Î£ Input[i+m, j+n, c] * Kernel[m,n,c,k] + Bias[k]
                m n c

where:
- (i,j) = spatial position
- k = output channel
- (m,n) = kernel position
- c = input channel
```

### Softmax Activation

```
P(class_i) = e^(z_i) / Î£ e^(z_j)
             j

where:
- z_i = logit for class i
- P(class_i) = probability of class i
- Î£ P(class_i) = 1 (probabilities sum to 1)
```

---

## ğŸ¯ Data Flow Summary

```
Audio File â†’ Preprocessing â†’ Spectrogram â†’ CNN â†’ Prediction
   (.wav)      (librosa)      (128x128)    (TF)   (Animal)
     â”‚              â”‚              â”‚          â”‚        â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              All steps automated in pipeline
```

---

## ğŸ’¾ Memory Requirements

### Training Phase
- **Spectrograms on disk**: ~5-10 MB per 100 images
- **Model in memory**: ~40 MB
- **Training batch**: ~50 MB (32 images)
- **Total RAM needed**: ~2-4 GB

### Inference Phase
- **Model in memory**: ~40 MB
- **Single image**: ~0.2 MB
- **Total RAM needed**: ~100 MB

---

## âš¡ Performance Characteristics

### Time Complexity
- **Spectrogram generation**: O(n log n) per audio file
- **CNN forward pass**: O(k Ã— h Ã— w Ã— c) per image
- **Training epoch**: O(N Ã— k Ã— h Ã— w Ã— c) for N samples

### Space Complexity
- **Model parameters**: O(P) where P â‰ˆ 2M parameters
- **Activation maps**: O(B Ã— H Ã— W Ã— C) per batch
- **Gradients**: O(P) during training

---

This architecture provides a robust, scalable system for animal sound classification with clear separation of concerns and efficient data flow.
